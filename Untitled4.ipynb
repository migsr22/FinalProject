{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240379, 455)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240379, 144)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:, df.isnull().mean() <.20]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def status(feature):\n",
    "    print('Processing', feature, ': OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing order_cols : OK\n"
     ]
    }
   ],
   "source": [
    "def order_cols():\n",
    "    global df\n",
    "    cols = list(df.columns.values) #Make a list of all of the columns in the df\n",
    "    cols.pop(cols.index('trr_id_code')) # Remove trr_id_code (primary key) from list\n",
    "    #cols.pop(cols.index('gstatus_ki')) #Remove gstatus_ki from list\n",
    "    cols.pop(cols.index('death')) #Remove death from list\n",
    "    df = df[['trr_id_code']+cols+['death']] #Create new dataframe with columns in the order #'gstatus_ki'\n",
    "    status('order_cols')\n",
    "    \n",
    "order_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101, 143], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def column_index(df, query_cols):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols,query_cols,sorter=sidx)]\n",
    "\n",
    "column_index(df, ['gstatus_ki', 'death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240379, 106)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_cols(df):\n",
    "    drop_cols = ['wl_org', 'rem_cd', 'dayswait_chron', 'end_date', 'init_date', 'wt_qual_date',\n",
    "                  'init_bmi_calc', 'dayswait_alloc', 'region', 'pri_payment_tcr_ki', 'pri_payment_trr_ki',\n",
    "                  'citizenship_don', 'cancer_site_don', 'diag_ki', 'organ', 'med_cond_trr', 'payback',\n",
    "                  'age_group', 'lt_one_week_don', 'data_transplant', 'opo_ctr_code', 'end_opo_ctr_code',\n",
    "                  'listing_ctr_code', 'citizenship', 'init_opo_ctr_code','death_fail_ki','ctr_code','px_stat_date', 'tx_date',\n",
    "                'admission_date', 'discharge_date', 'trr_id_code', 'grf_stat_ki', 'px_stat', 'gstatus_ki', 'pstatus', 'ptime', 'dwfg_ki']\n",
    "    df.drop(drop_cols, inplace=True, axis=1)\n",
    "    return df.shape\n",
    "    status('drop_cols')\n",
    "\n",
    "drop_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143647, 106)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_rows():\n",
    "    global df\n",
    "    df.dropna(how='any', inplace=True, axis=0)\n",
    "    return df.shape\n",
    "    status('drop_rows')\n",
    "\n",
    "drop_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing format_funcstat_tcr : OK\n"
     ]
    }
   ],
   "source": [
    "def format_funcstat_tcr(df):\n",
    "    funcstat_cols = ['func_stat_tcr']\n",
    "    for i in funcstat_cols:\n",
    "        df[i] = df[i].map({2100:0, 4100:0, 1:0, 998:0, 996:0,\n",
    "                            2090:1, 4090:1,\n",
    "                            2080:2, 4080:2,\n",
    "                            2070:3, 4070:3,\n",
    "                            2060:4, 4060:4,\n",
    "                            2050:5, 4050:5, 2:5,\n",
    "                            2040:6, 4040:6,\n",
    "                            2030:7,\n",
    "                            2020:8,\n",
    "                            2010:9, \n",
    "                            3:10})\n",
    "    status('format_funcstat_tcr')\n",
    "    \n",
    "format_funcstat_tcr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing format_funcstat_trr : OK\n"
     ]
    }
   ],
   "source": [
    "def format_funcstat_trr(df):\n",
    "    funcstat_cols = ['func_stat_trr']\n",
    "    for i in funcstat_cols:\n",
    "        df[i] = df[i].map({2100:0, 1:0, 996:0, 998:0,\n",
    "                            2090:1,\n",
    "                            2080:2,\n",
    "                            2070:3,\n",
    "                            2060:4,\n",
    "                            2050:5, 2:5,\n",
    "                            2040:6,\n",
    "                            2030:7,\n",
    "                            2020:8,\n",
    "                            2010:9,\n",
    "                            3:10})\n",
    "    status('format_funcstat_trr')\n",
    "    \n",
    "format_funcstat_trr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def format_dates(df):\n",
    "#     date_cols = ['admission_date', 'discharge_date']\n",
    "#     for i in date_cols:\n",
    "#         df[i] = pd.to_datetime(df[i])\n",
    "#     status('format_dates')\n",
    "\n",
    "# format_dates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_days(df):\n",
    "#     df['days'] = df['discharge_date'] - df['admission_date']\n",
    "#     drop_date_cols = ['discharge_date', 'admission_date']\n",
    "#     df.drop(drop_date_cols, inplace=True, axis=1)\n",
    "#     status('create_days')\n",
    "    \n",
    "# create_days(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def format_days(df):\n",
    "#     df['days_total'] = df['days'].str.split('')\n",
    "#     status('format_days')\n",
    "    \n",
    "# format_days(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing format_yn : OK\n"
     ]
    }
   ],
   "source": [
    "def format_yn(df):\n",
    "    #dwfg_ki\n",
    "    yn_cols = ['data_waitlist', 'don_retyp', 'donation','first_wk_dial', 'on_dialysis', 'prev_ki_tx', 'prev_tx', 'prev_tx_any']\n",
    "    ynu_cols = ['diabetes_don', 'dial_trr','drugtrt_copd', 'exh_perit_access', 'exh_vasc_access',\n",
    "                'hist_cancer_don', 'hist_cig_don', 'hist_hypertens_don', 'malig', 'malig_tcr_ki',\n",
    "                'malig_trr', 'perip_vasc', 'pre_tx_txfus']\n",
    "    #grf_stat_ki\n",
    "    yes_no_u_cols = yn_cols + ynu_cols\n",
    "    for i in yes_no_u_cols:\n",
    "        df[i] = df[i].map({'Y':1,'N':0, 'U':0})\n",
    "    status('format_yn')\n",
    "\n",
    "format_yn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing format_gender : OK\n"
     ]
    }
   ],
   "source": [
    "def format_gender(df):\n",
    "    gender_cols = ['gender', 'gender_don']\n",
    "    for i in gender_cols:\n",
    "        df[i] = df[i].map({'M':1, 'F':0})\n",
    "    status('format_gender')\n",
    "\n",
    "format_gender(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns_to_encode = ['abo', 'abo_don', 'cmv_igg', 'cmv_igm', 'cmv_status',\n",
    "#                      'ebv_serostatus', 'hbv_core', 'hbv_sur_antigen',\n",
    "#                      'hcv_serostatus', 'hbv_core_don', 'hbv_sur_antigen_don',\n",
    "#                      'abo_mat', 'diab', 'don_ty', 'education', 'end_stat',\n",
    "#                      'end_stat_ki', 'ethcat', 'ethcat_don', 'ethnicity', 'px_stat',\n",
    "#                      'share_ty', 'tx_procedur_ty_ki', 'init_stat', 'txkid']\n",
    "# encoded_cols = pd.get_dummies(df, columns = columns_to_encode, drop_first=True)\n",
    "# df.drop(columns_to_encode, inplace=True, axis=1)\n",
    "# newdf = pd.concat([df, encoded_cols], axis=1)\n",
    "# newdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def encode_columns(df):\n",
    "#     columns_to_encode = ['abo', 'abo_don', 'cmv_igg', 'cmv_igm', 'cmv_status',\n",
    "#                      'ebv_serostatus', 'hbv_core', 'hbv_sur_antigen',\n",
    "#                      'hcv_serostatus', 'hbv_core_don', 'hbv_sur_antigen_don',\n",
    "#                      'abo_mat', 'diab', 'don_ty', 'education', 'end_stat',\n",
    "#                      'end_stat_ki', 'ethcat', 'ethcat_don', 'ethnicity', 'px_stat',\n",
    "#                      'share_ty', 'tx_procedur_ty_ki', 'init_stat', 'txkid']\n",
    "\n",
    "\n",
    "#     for i in columns_to_encode:\n",
    "#         encoded_cols = pd.get_dummies(df, columns = columns_to_encode, drop_first =True)\n",
    "#         df.drop(columns_to_encode, inplace=True, axis=1)\n",
    "#         newdf = pd.concat([df, encoded_cols], axis = 1)\n",
    "#         newdf.shape\n",
    "#         status('encode_columns')\n",
    "#         return df.shape\n",
    "# encode_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 7, ..., 7, 6, 0], dtype=int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "pd.Categorical(df.abo).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143647, 106)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv(r'C:\\Users\\Agi\\Desktop\\DropBox\\Dropbox\\Classes\\ITSS 4354\\Final Project\\chech.csv' , encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "categorical_vars = ['abo', 'perm_state', 'txkid', 'hbv_core_don', 'hbv_sur_antigen_don', 'abo_don', 'don_ty',\n",
    "                    'home_state_don', 'cmv_igg', 'cmv_igm', 'ebv_serostatus', 'hbv_core',\n",
    "                    'hbv_sur_antigen', 'hcv_serostatus', 'hiv_serostatus', 'cmv_status']\n",
    "#px_stat\n",
    "\n",
    "for c in categorical_vars:\n",
    "    df[c] = pd.Categorical(df[c]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'num_leaves': 7,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbose': 0\n",
    "}\n",
    "boost_rounds_form = 80\n",
    "model_form = LGBMClassifier(**lgb_params, num_boost_round=boost_rounds_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143647, 106)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, 105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[\"death\"].value_counts().plot(kind='bar')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's binary_logloss: 0.342716 + 0.00304262\n",
      "[100]\tcv_agg's binary_logloss: 0.326651 + 0.00349081\n"
     ]
    }
   ],
   "source": [
    "lgb_train = Dataset(data = X, label = y,categorical_feature=['abo', 'perm_state', 'txkid', 'hbv_core_don', 'hbv_sur_antigen_don', 'abo_don', 'don_ty',\n",
    "                    'home_state_don', 'cmv_igg', 'cmv_igm', 'ebv_serostatus', 'hbv_core',\n",
    "                    'hbv_sur_antigen', 'hcv_serostatus', 'hiv_serostatus', 'cmv_status'])\n",
    "cv = lgb.cv(lgb_params, \n",
    "              lgb_train, \n",
    "              nfold = 10,\n",
    "              num_boost_round=100, \n",
    "              early_stopping_rounds=15,\n",
    "              stratified=False, \n",
    "              verbose_eval=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_logloss-mean': [0.6486082711650738,\n",
       "  0.61102692244361478,\n",
       "  0.57955728920350358,\n",
       "  0.55351989683836877,\n",
       "  0.52977731040322085,\n",
       "  0.51008693702823193,\n",
       "  0.49340403192481352,\n",
       "  0.4779659801030644,\n",
       "  0.4647134203075064,\n",
       "  0.45323108550621266,\n",
       "  0.44313577576493374,\n",
       "  0.43382418068122808,\n",
       "  0.42588008034475777,\n",
       "  0.41839313013558083,\n",
       "  0.4119145508027649,\n",
       "  0.40615753553610656,\n",
       "  0.40100242694285732,\n",
       "  0.39629471941253341,\n",
       "  0.3919391063060898,\n",
       "  0.38790427104633235,\n",
       "  0.38426025225898269,\n",
       "  0.38110348102951119,\n",
       "  0.37835360257895445,\n",
       "  0.37554099996661172,\n",
       "  0.37309571343717446,\n",
       "  0.37091789606334002,\n",
       "  0.36857918662159384,\n",
       "  0.3664794901880285,\n",
       "  0.36449941923032986,\n",
       "  0.36294987893277092,\n",
       "  0.36118412857926235,\n",
       "  0.35953412900140774,\n",
       "  0.35821942199994994,\n",
       "  0.35678045855359186,\n",
       "  0.35553689860701454,\n",
       "  0.35434990814539025,\n",
       "  0.35334203619131582,\n",
       "  0.35226691228083928,\n",
       "  0.35120239227625716,\n",
       "  0.35030742575333162,\n",
       "  0.34933636448558347,\n",
       "  0.34849291171472829,\n",
       "  0.34754218783561514,\n",
       "  0.34683899010815167,\n",
       "  0.34610062331541058,\n",
       "  0.34539819023622698,\n",
       "  0.344576473615331,\n",
       "  0.34401491112433058,\n",
       "  0.34338541455343469,\n",
       "  0.34271579230506322,\n",
       "  0.34216022414970187,\n",
       "  0.3415452829583851,\n",
       "  0.34089687893194998,\n",
       "  0.34031743584544216,\n",
       "  0.33971427204428439,\n",
       "  0.33919572623419914,\n",
       "  0.3386739739502917,\n",
       "  0.33818997271188889,\n",
       "  0.33768245632427096,\n",
       "  0.33724209375782294,\n",
       "  0.33684027729833016,\n",
       "  0.33640586582404108,\n",
       "  0.33601953276368335,\n",
       "  0.33566095920317934,\n",
       "  0.33523771958433635,\n",
       "  0.3348232931917754,\n",
       "  0.33447682667585271,\n",
       "  0.33412844716930773,\n",
       "  0.33379041206333809,\n",
       "  0.33346685491807204,\n",
       "  0.33313634261784786,\n",
       "  0.33277648240461394,\n",
       "  0.33241068496623349,\n",
       "  0.33213681902336578,\n",
       "  0.33183099679270411,\n",
       "  0.33153944769625293,\n",
       "  0.33130896748761079,\n",
       "  0.33106358298001065,\n",
       "  0.33082122367413608,\n",
       "  0.33056125399267355,\n",
       "  0.33026753859618785,\n",
       "  0.32998831251620331,\n",
       "  0.32980985309688049,\n",
       "  0.32952964030319648,\n",
       "  0.32927814430834873,\n",
       "  0.32907055326954898,\n",
       "  0.32894106483020197,\n",
       "  0.32875082616975754,\n",
       "  0.32852656197072322,\n",
       "  0.32828506169451754,\n",
       "  0.32805415130719678,\n",
       "  0.32787500333320613,\n",
       "  0.327656823306544,\n",
       "  0.32749870430904698,\n",
       "  0.32729418663189075,\n",
       "  0.32718894008350918,\n",
       "  0.32706897413328523,\n",
       "  0.32688824599937183,\n",
       "  0.32675010472748739,\n",
       "  0.32665083793307764],\n",
       " 'binary_logloss-stdv': [0.00040168671082116913,\n",
       "  0.00065171710405077907,\n",
       "  0.00084197816585456007,\n",
       "  0.0009479085721212639,\n",
       "  0.00094898819758738764,\n",
       "  0.0010440297566985165,\n",
       "  0.0012782406788052621,\n",
       "  0.0013291127247697038,\n",
       "  0.0014319937187972287,\n",
       "  0.0016676936307454637,\n",
       "  0.001769251615788544,\n",
       "  0.0019323383734714654,\n",
       "  0.0019262162722666245,\n",
       "  0.0018409815423532992,\n",
       "  0.0021413833455420765,\n",
       "  0.0023049187004031031,\n",
       "  0.0022163493776085094,\n",
       "  0.0024079493011731766,\n",
       "  0.0024151886518852376,\n",
       "  0.0025954210465948544,\n",
       "  0.0024765176145457512,\n",
       "  0.0025591735272831092,\n",
       "  0.0026474494754233492,\n",
       "  0.0024691302402880355,\n",
       "  0.0023609749353175171,\n",
       "  0.0024578231607099601,\n",
       "  0.0028265097851736362,\n",
       "  0.002865106643315133,\n",
       "  0.002954506405136656,\n",
       "  0.0029045081863401604,\n",
       "  0.0029095083738251665,\n",
       "  0.0030804958669255495,\n",
       "  0.0031859862192606526,\n",
       "  0.0030622232536174207,\n",
       "  0.0029281720765908714,\n",
       "  0.0028693872377175537,\n",
       "  0.0028132511574854913,\n",
       "  0.0028834655218061421,\n",
       "  0.0030281493016092982,\n",
       "  0.0030189334611903291,\n",
       "  0.0029771000456491792,\n",
       "  0.0030261951361206327,\n",
       "  0.0029993675695092503,\n",
       "  0.0029911421605940294,\n",
       "  0.0029114409339734467,\n",
       "  0.0030597897329699081,\n",
       "  0.0029850955681704561,\n",
       "  0.0030106568624326193,\n",
       "  0.0030360274516772084,\n",
       "  0.0030426182772535378,\n",
       "  0.0030777826570710385,\n",
       "  0.0031965324671431043,\n",
       "  0.0031072566431572558,\n",
       "  0.0031224593167689229,\n",
       "  0.0030878204537092093,\n",
       "  0.0031478946505265515,\n",
       "  0.0032479419561217021,\n",
       "  0.0033038441200711763,\n",
       "  0.0032321199299193606,\n",
       "  0.0032494164117819364,\n",
       "  0.0032758941355061585,\n",
       "  0.0032330611283561271,\n",
       "  0.0032019327764058756,\n",
       "  0.0032459498857945147,\n",
       "  0.0032838881383073643,\n",
       "  0.0032031790705764921,\n",
       "  0.0031608289632727104,\n",
       "  0.0032351246626432036,\n",
       "  0.0032276611357299994,\n",
       "  0.0032312150753926465,\n",
       "  0.0032411701780412556,\n",
       "  0.0032990409554368152,\n",
       "  0.0034044339362921195,\n",
       "  0.0034964306447045272,\n",
       "  0.0034547030490049385,\n",
       "  0.0033829752166734698,\n",
       "  0.0033989451603948805,\n",
       "  0.0033721852288490666,\n",
       "  0.0033689018925079895,\n",
       "  0.003365037311944014,\n",
       "  0.0033539288677817206,\n",
       "  0.0032639788840905684,\n",
       "  0.0032963692763640301,\n",
       "  0.0032932265594315217,\n",
       "  0.0032949444832786126,\n",
       "  0.0033289405815952939,\n",
       "  0.0033474737368113321,\n",
       "  0.0033070289940679812,\n",
       "  0.0033669053988135086,\n",
       "  0.0034610249905177729,\n",
       "  0.003414580607982816,\n",
       "  0.0033866637150325187,\n",
       "  0.0033812664246511272,\n",
       "  0.0033738815674481605,\n",
       "  0.0034437462538332107,\n",
       "  0.0034489758545093565,\n",
       "  0.0034840367463737859,\n",
       "  0.0034190515506406813,\n",
       "  0.00349866456532952,\n",
       "  0.0034908129785751535]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 - (sum(cv['l2-mean']) / float(len(cv['l2-mean'])))\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(sum(cv['l2-stdv']) / float(len(cv['l2-stdv'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.637882\n",
      "[2]\ttraining's binary_logloss: 0.592695\n",
      "[3]\ttraining's binary_logloss: 0.554653\n",
      "[4]\ttraining's binary_logloss: 0.522649\n",
      "[5]\ttraining's binary_logloss: 0.495198\n",
      "[6]\ttraining's binary_logloss: 0.471861\n",
      "[7]\ttraining's binary_logloss: 0.451286\n",
      "[8]\ttraining's binary_logloss: 0.433512\n",
      "[9]\ttraining's binary_logloss: 0.418133\n",
      "[10]\ttraining's binary_logloss: 0.40481\n",
      "[11]\ttraining's binary_logloss: 0.392995\n",
      "[12]\ttraining's binary_logloss: 0.382701\n",
      "[13]\ttraining's binary_logloss: 0.373687\n",
      "[14]\ttraining's binary_logloss: 0.365748\n",
      "[15]\ttraining's binary_logloss: 0.358512\n",
      "[16]\ttraining's binary_logloss: 0.352288\n",
      "[17]\ttraining's binary_logloss: 0.346777\n",
      "[18]\ttraining's binary_logloss: 0.341774\n",
      "[19]\ttraining's binary_logloss: 0.337071\n",
      "[20]\ttraining's binary_logloss: 0.332913\n",
      "[21]\ttraining's binary_logloss: 0.329211\n",
      "[22]\ttraining's binary_logloss: 0.326193\n",
      "[23]\ttraining's binary_logloss: 0.323062\n",
      "[24]\ttraining's binary_logloss: 0.32046\n",
      "[25]\ttraining's binary_logloss: 0.318332\n",
      "[26]\ttraining's binary_logloss: 0.31593\n",
      "[27]\ttraining's binary_logloss: 0.314066\n",
      "[28]\ttraining's binary_logloss: 0.312369\n",
      "[29]\ttraining's binary_logloss: 0.310307\n",
      "[30]\ttraining's binary_logloss: 0.308911\n",
      "[31]\ttraining's binary_logloss: 0.307279\n",
      "[32]\ttraining's binary_logloss: 0.306047\n",
      "[33]\ttraining's binary_logloss: 0.304799\n",
      "[34]\ttraining's binary_logloss: 0.303684\n",
      "[35]\ttraining's binary_logloss: 0.302327\n",
      "[36]\ttraining's binary_logloss: 0.301427\n",
      "[37]\ttraining's binary_logloss: 0.3001\n",
      "[38]\ttraining's binary_logloss: 0.299238\n",
      "[39]\ttraining's binary_logloss: 0.298359\n",
      "[40]\ttraining's binary_logloss: 0.297313\n",
      "[41]\ttraining's binary_logloss: 0.29628\n",
      "[42]\ttraining's binary_logloss: 0.295584\n",
      "[43]\ttraining's binary_logloss: 0.294672\n",
      "[44]\ttraining's binary_logloss: 0.29401\n",
      "[45]\ttraining's binary_logloss: 0.293372\n",
      "[46]\ttraining's binary_logloss: 0.292705\n",
      "[47]\ttraining's binary_logloss: 0.292069\n",
      "[48]\ttraining's binary_logloss: 0.291497\n",
      "[49]\ttraining's binary_logloss: 0.29089\n",
      "[50]\ttraining's binary_logloss: 0.289995\n",
      "[51]\ttraining's binary_logloss: 0.289384\n",
      "[52]\ttraining's binary_logloss: 0.288914\n",
      "[53]\ttraining's binary_logloss: 0.288216\n",
      "[54]\ttraining's binary_logloss: 0.287722\n",
      "[55]\ttraining's binary_logloss: 0.287018\n",
      "[56]\ttraining's binary_logloss: 0.286541\n",
      "[57]\ttraining's binary_logloss: 0.286079\n",
      "[58]\ttraining's binary_logloss: 0.285633\n",
      "[59]\ttraining's binary_logloss: 0.285045\n",
      "[60]\ttraining's binary_logloss: 0.284637\n",
      "[61]\ttraining's binary_logloss: 0.28421\n",
      "[62]\ttraining's binary_logloss: 0.283803\n",
      "[63]\ttraining's binary_logloss: 0.283409\n",
      "[64]\ttraining's binary_logloss: 0.28303\n",
      "[65]\ttraining's binary_logloss: 0.282383\n",
      "[66]\ttraining's binary_logloss: 0.28203\n",
      "[67]\ttraining's binary_logloss: 0.281662\n",
      "[68]\ttraining's binary_logloss: 0.281121\n",
      "[69]\ttraining's binary_logloss: 0.280738\n",
      "[70]\ttraining's binary_logloss: 0.280376\n",
      "[71]\ttraining's binary_logloss: 0.28003\n",
      "[72]\ttraining's binary_logloss: 0.27971\n",
      "[73]\ttraining's binary_logloss: 0.279366\n",
      "[74]\ttraining's binary_logloss: 0.278973\n",
      "[75]\ttraining's binary_logloss: 0.278647\n",
      "[76]\ttraining's binary_logloss: 0.27814\n",
      "[77]\ttraining's binary_logloss: 0.277788\n",
      "[78]\ttraining's binary_logloss: 0.277448\n",
      "[79]\ttraining's binary_logloss: 0.277092\n",
      "[80]\ttraining's binary_logloss: 0.276782\n",
      "[81]\ttraining's binary_logloss: 0.276432\n",
      "[82]\ttraining's binary_logloss: 0.276058\n",
      "[83]\ttraining's binary_logloss: 0.275671\n",
      "[84]\ttraining's binary_logloss: 0.275328\n",
      "[85]\ttraining's binary_logloss: 0.274988\n",
      "[86]\ttraining's binary_logloss: 0.274674\n",
      "[87]\ttraining's binary_logloss: 0.274369\n",
      "[88]\ttraining's binary_logloss: 0.274073\n",
      "[89]\ttraining's binary_logloss: 0.273688\n",
      "[90]\ttraining's binary_logloss: 0.273376\n",
      "[91]\ttraining's binary_logloss: 0.273106\n",
      "[92]\ttraining's binary_logloss: 0.272863\n",
      "[93]\ttraining's binary_logloss: 0.272574\n",
      "[94]\ttraining's binary_logloss: 0.27229\n",
      "[95]\ttraining's binary_logloss: 0.271976\n",
      "[96]\ttraining's binary_logloss: 0.271703\n",
      "[97]\ttraining's binary_logloss: 0.271413\n",
      "[98]\ttraining's binary_logloss: 0.271168\n",
      "[99]\ttraining's binary_logloss: 0.270844\n",
      "[100]\ttraining's binary_logloss: 0.270586\n",
      "[101]\ttraining's binary_logloss: 0.270294\n",
      "[102]\ttraining's binary_logloss: 0.270014\n",
      "[103]\ttraining's binary_logloss: 0.269744\n",
      "[104]\ttraining's binary_logloss: 0.269535\n",
      "[105]\ttraining's binary_logloss: 0.269278\n",
      "[106]\ttraining's binary_logloss: 0.268863\n",
      "[107]\ttraining's binary_logloss: 0.268571\n",
      "[108]\ttraining's binary_logloss: 0.268295\n",
      "[109]\ttraining's binary_logloss: 0.267975\n",
      "[110]\ttraining's binary_logloss: 0.267745\n",
      "[111]\ttraining's binary_logloss: 0.267521\n",
      "[112]\ttraining's binary_logloss: 0.267295\n",
      "[113]\ttraining's binary_logloss: 0.267056\n",
      "[114]\ttraining's binary_logloss: 0.266827\n",
      "[115]\ttraining's binary_logloss: 0.26653\n",
      "[116]\ttraining's binary_logloss: 0.266248\n",
      "[117]\ttraining's binary_logloss: 0.26588\n",
      "[118]\ttraining's binary_logloss: 0.265511\n",
      "[119]\ttraining's binary_logloss: 0.265224\n",
      "[120]\ttraining's binary_logloss: 0.264989\n",
      "[121]\ttraining's binary_logloss: 0.264697\n",
      "[122]\ttraining's binary_logloss: 0.264472\n",
      "[123]\ttraining's binary_logloss: 0.264196\n",
      "[124]\ttraining's binary_logloss: 0.263956\n",
      "[125]\ttraining's binary_logloss: 0.263713\n",
      "[126]\ttraining's binary_logloss: 0.263464\n",
      "[127]\ttraining's binary_logloss: 0.263221\n",
      "[128]\ttraining's binary_logloss: 0.262894\n",
      "[129]\ttraining's binary_logloss: 0.26266\n",
      "[130]\ttraining's binary_logloss: 0.262385\n",
      "[131]\ttraining's binary_logloss: 0.26213\n",
      "[132]\ttraining's binary_logloss: 0.26193\n",
      "[133]\ttraining's binary_logloss: 0.261659\n",
      "[134]\ttraining's binary_logloss: 0.261376\n",
      "[135]\ttraining's binary_logloss: 0.261173\n",
      "[136]\ttraining's binary_logloss: 0.260935\n",
      "[137]\ttraining's binary_logloss: 0.260607\n",
      "[138]\ttraining's binary_logloss: 0.260364\n",
      "[139]\ttraining's binary_logloss: 0.260128\n",
      "[140]\ttraining's binary_logloss: 0.259938\n",
      "[141]\ttraining's binary_logloss: 0.259693\n",
      "[142]\ttraining's binary_logloss: 0.259466\n",
      "[143]\ttraining's binary_logloss: 0.259298\n",
      "[144]\ttraining's binary_logloss: 0.259075\n",
      "[145]\ttraining's binary_logloss: 0.258834\n",
      "[146]\ttraining's binary_logloss: 0.258468\n",
      "[147]\ttraining's binary_logloss: 0.258243\n",
      "[148]\ttraining's binary_logloss: 0.258027\n",
      "[149]\ttraining's binary_logloss: 0.257836\n",
      "[150]\ttraining's binary_logloss: 0.257562\n",
      "[151]\ttraining's binary_logloss: 0.257298\n",
      "[152]\ttraining's binary_logloss: 0.257049\n",
      "[153]\ttraining's binary_logloss: 0.256811\n",
      "[154]\ttraining's binary_logloss: 0.256635\n",
      "[155]\ttraining's binary_logloss: 0.256406\n",
      "[156]\ttraining's binary_logloss: 0.256156\n",
      "[157]\ttraining's binary_logloss: 0.255947\n",
      "[158]\ttraining's binary_logloss: 0.255761\n",
      "[159]\ttraining's binary_logloss: 0.255548\n",
      "[160]\ttraining's binary_logloss: 0.255275\n",
      "[161]\ttraining's binary_logloss: 0.255062\n",
      "[162]\ttraining's binary_logloss: 0.254809\n",
      "[163]\ttraining's binary_logloss: 0.254572\n",
      "[164]\ttraining's binary_logloss: 0.254357\n",
      "[165]\ttraining's binary_logloss: 0.254047\n",
      "[166]\ttraining's binary_logloss: 0.253844\n",
      "[167]\ttraining's binary_logloss: 0.253615\n",
      "[168]\ttraining's binary_logloss: 0.253448\n",
      "[169]\ttraining's binary_logloss: 0.253221\n",
      "[170]\ttraining's binary_logloss: 0.25301\n",
      "[171]\ttraining's binary_logloss: 0.252767\n",
      "[172]\ttraining's binary_logloss: 0.252526\n",
      "[173]\ttraining's binary_logloss: 0.252338\n",
      "[174]\ttraining's binary_logloss: 0.252119\n",
      "[175]\ttraining's binary_logloss: 0.251926\n",
      "[176]\ttraining's binary_logloss: 0.251648\n",
      "[177]\ttraining's binary_logloss: 0.251461\n",
      "[178]\ttraining's binary_logloss: 0.251235\n",
      "[179]\ttraining's binary_logloss: 0.250993\n",
      "[180]\ttraining's binary_logloss: 0.250774\n",
      "[181]\ttraining's binary_logloss: 0.250505\n",
      "[182]\ttraining's binary_logloss: 0.250269\n",
      "[183]\ttraining's binary_logloss: 0.250054\n",
      "[184]\ttraining's binary_logloss: 0.249813\n",
      "[185]\ttraining's binary_logloss: 0.249621\n",
      "[186]\ttraining's binary_logloss: 0.249377\n",
      "[187]\ttraining's binary_logloss: 0.24918\n",
      "[188]\ttraining's binary_logloss: 0.248943\n",
      "[189]\ttraining's binary_logloss: 0.248708\n",
      "[190]\ttraining's binary_logloss: 0.248465\n",
      "[191]\ttraining's binary_logloss: 0.2483\n",
      "[192]\ttraining's binary_logloss: 0.248128\n",
      "[193]\ttraining's binary_logloss: 0.24786\n",
      "[194]\ttraining's binary_logloss: 0.247656\n",
      "[195]\ttraining's binary_logloss: 0.247472\n",
      "[196]\ttraining's binary_logloss: 0.247281\n",
      "[197]\ttraining's binary_logloss: 0.247132\n",
      "[198]\ttraining's binary_logloss: 0.246934\n",
      "[199]\ttraining's binary_logloss: 0.246729\n",
      "[200]\ttraining's binary_logloss: 0.246593\n",
      "[201]\ttraining's binary_logloss: 0.246353\n",
      "[202]\ttraining's binary_logloss: 0.246131\n",
      "[203]\ttraining's binary_logloss: 0.245972\n",
      "[204]\ttraining's binary_logloss: 0.245687\n",
      "[205]\ttraining's binary_logloss: 0.245488\n",
      "[206]\ttraining's binary_logloss: 0.245269\n",
      "[207]\ttraining's binary_logloss: 0.245051\n",
      "[208]\ttraining's binary_logloss: 0.244871\n",
      "[209]\ttraining's binary_logloss: 0.244632\n",
      "[210]\ttraining's binary_logloss: 0.24448\n",
      "[211]\ttraining's binary_logloss: 0.244264\n",
      "[212]\ttraining's binary_logloss: 0.244058\n",
      "[213]\ttraining's binary_logloss: 0.24387\n",
      "[214]\ttraining's binary_logloss: 0.243678\n",
      "[215]\ttraining's binary_logloss: 0.243509\n",
      "[216]\ttraining's binary_logloss: 0.243306\n",
      "[217]\ttraining's binary_logloss: 0.24308\n",
      "[218]\ttraining's binary_logloss: 0.242793\n",
      "[219]\ttraining's binary_logloss: 0.242541\n",
      "[220]\ttraining's binary_logloss: 0.242375\n",
      "[221]\ttraining's binary_logloss: 0.242159\n",
      "[222]\ttraining's binary_logloss: 0.241883\n",
      "[223]\ttraining's binary_logloss: 0.24166\n",
      "[224]\ttraining's binary_logloss: 0.24147\n",
      "[225]\ttraining's binary_logloss: 0.241222\n",
      "[226]\ttraining's binary_logloss: 0.240978\n",
      "[227]\ttraining's binary_logloss: 0.240728\n",
      "[228]\ttraining's binary_logloss: 0.240557\n",
      "[229]\ttraining's binary_logloss: 0.240316\n",
      "[230]\ttraining's binary_logloss: 0.240124\n",
      "[231]\ttraining's binary_logloss: 0.239985\n",
      "[232]\ttraining's binary_logloss: 0.239771\n",
      "[233]\ttraining's binary_logloss: 0.239541\n",
      "[234]\ttraining's binary_logloss: 0.239386\n",
      "[235]\ttraining's binary_logloss: 0.239146\n",
      "[236]\ttraining's binary_logloss: 0.239016\n",
      "[237]\ttraining's binary_logloss: 0.23882\n",
      "[238]\ttraining's binary_logloss: 0.238589\n",
      "[239]\ttraining's binary_logloss: 0.238383\n",
      "[240]\ttraining's binary_logloss: 0.238149\n",
      "[241]\ttraining's binary_logloss: 0.237913\n",
      "[242]\ttraining's binary_logloss: 0.237733\n",
      "[243]\ttraining's binary_logloss: 0.237489\n",
      "[244]\ttraining's binary_logloss: 0.237222\n",
      "[245]\ttraining's binary_logloss: 0.237006\n",
      "[246]\ttraining's binary_logloss: 0.236832\n",
      "[247]\ttraining's binary_logloss: 0.236629\n",
      "[248]\ttraining's binary_logloss: 0.23648\n",
      "[249]\ttraining's binary_logloss: 0.236243\n",
      "[250]\ttraining's binary_logloss: 0.236021\n",
      "[251]\ttraining's binary_logloss: 0.235855\n",
      "[252]\ttraining's binary_logloss: 0.235665\n",
      "[253]\ttraining's binary_logloss: 0.235484\n",
      "[254]\ttraining's binary_logloss: 0.235343\n",
      "[255]\ttraining's binary_logloss: 0.235176\n",
      "[256]\ttraining's binary_logloss: 0.234992\n",
      "[257]\ttraining's binary_logloss: 0.234774\n",
      "[258]\ttraining's binary_logloss: 0.234558\n",
      "[259]\ttraining's binary_logloss: 0.234366\n",
      "[260]\ttraining's binary_logloss: 0.234165\n",
      "[261]\ttraining's binary_logloss: 0.23399\n",
      "[262]\ttraining's binary_logloss: 0.233804\n",
      "[263]\ttraining's binary_logloss: 0.233657\n",
      "[264]\ttraining's binary_logloss: 0.233439\n",
      "[265]\ttraining's binary_logloss: 0.233248\n",
      "[266]\ttraining's binary_logloss: 0.232943\n",
      "[267]\ttraining's binary_logloss: 0.232739\n",
      "[268]\ttraining's binary_logloss: 0.232503\n",
      "[269]\ttraining's binary_logloss: 0.232321\n",
      "[270]\ttraining's binary_logloss: 0.23214\n",
      "[271]\ttraining's binary_logloss: 0.231965\n",
      "[272]\ttraining's binary_logloss: 0.23174\n",
      "[273]\ttraining's binary_logloss: 0.231518\n",
      "[274]\ttraining's binary_logloss: 0.231366\n",
      "[275]\ttraining's binary_logloss: 0.23123\n",
      "[276]\ttraining's binary_logloss: 0.231043\n",
      "[277]\ttraining's binary_logloss: 0.230871\n",
      "[278]\ttraining's binary_logloss: 0.23063\n",
      "[279]\ttraining's binary_logloss: 0.230398\n",
      "[280]\ttraining's binary_logloss: 0.230205\n",
      "[281]\ttraining's binary_logloss: 0.230034\n",
      "[282]\ttraining's binary_logloss: 0.229863\n",
      "[283]\ttraining's binary_logloss: 0.229635\n",
      "[284]\ttraining's binary_logloss: 0.229426\n",
      "[285]\ttraining's binary_logloss: 0.229304\n",
      "[286]\ttraining's binary_logloss: 0.229161\n",
      "[287]\ttraining's binary_logloss: 0.228982\n",
      "[288]\ttraining's binary_logloss: 0.228766\n",
      "[289]\ttraining's binary_logloss: 0.228599\n",
      "[290]\ttraining's binary_logloss: 0.22837\n",
      "[291]\ttraining's binary_logloss: 0.228252\n",
      "[292]\ttraining's binary_logloss: 0.228135\n",
      "[293]\ttraining's binary_logloss: 0.227935\n",
      "[294]\ttraining's binary_logloss: 0.227821\n",
      "[295]\ttraining's binary_logloss: 0.227671\n",
      "[296]\ttraining's binary_logloss: 0.227467\n",
      "[297]\ttraining's binary_logloss: 0.227233\n",
      "[298]\ttraining's binary_logloss: 0.227072\n",
      "[299]\ttraining's binary_logloss: 0.226892\n",
      "[300]\ttraining's binary_logloss: 0.226711\n",
      "[301]\ttraining's binary_logloss: 0.226526\n",
      "[302]\ttraining's binary_logloss: 0.226321\n",
      "[303]\ttraining's binary_logloss: 0.226222\n",
      "[304]\ttraining's binary_logloss: 0.226009\n",
      "[305]\ttraining's binary_logloss: 0.225817\n",
      "[306]\ttraining's binary_logloss: 0.225585\n",
      "[307]\ttraining's binary_logloss: 0.225374\n",
      "[308]\ttraining's binary_logloss: 0.225167\n",
      "[309]\ttraining's binary_logloss: 0.224982\n",
      "[310]\ttraining's binary_logloss: 0.224851\n",
      "[311]\ttraining's binary_logloss: 0.22472\n",
      "[312]\ttraining's binary_logloss: 0.224519\n",
      "[313]\ttraining's binary_logloss: 0.224412\n",
      "[314]\ttraining's binary_logloss: 0.224239\n",
      "[315]\ttraining's binary_logloss: 0.224084\n",
      "[316]\ttraining's binary_logloss: 0.223866\n",
      "[317]\ttraining's binary_logloss: 0.223695\n",
      "[318]\ttraining's binary_logloss: 0.223496\n",
      "[319]\ttraining's binary_logloss: 0.223395\n",
      "[320]\ttraining's binary_logloss: 0.223211\n",
      "[321]\ttraining's binary_logloss: 0.223003\n",
      "[322]\ttraining's binary_logloss: 0.222826\n",
      "[323]\ttraining's binary_logloss: 0.222701\n",
      "[324]\ttraining's binary_logloss: 0.222544\n",
      "[325]\ttraining's binary_logloss: 0.222378\n",
      "[326]\ttraining's binary_logloss: 0.222141\n",
      "[327]\ttraining's binary_logloss: 0.221955\n",
      "[328]\ttraining's binary_logloss: 0.221789\n",
      "[329]\ttraining's binary_logloss: 0.221613\n",
      "[330]\ttraining's binary_logloss: 0.221474\n",
      "[331]\ttraining's binary_logloss: 0.221246\n",
      "[332]\ttraining's binary_logloss: 0.221133\n",
      "[333]\ttraining's binary_logloss: 0.220972\n",
      "[334]\ttraining's binary_logloss: 0.220821\n",
      "[335]\ttraining's binary_logloss: 0.220573\n",
      "[336]\ttraining's binary_logloss: 0.22041\n",
      "[337]\ttraining's binary_logloss: 0.220215\n",
      "[338]\ttraining's binary_logloss: 0.220071\n",
      "[339]\ttraining's binary_logloss: 0.219898\n",
      "[340]\ttraining's binary_logloss: 0.219742\n",
      "[341]\ttraining's binary_logloss: 0.219554\n",
      "[342]\ttraining's binary_logloss: 0.219352\n",
      "[343]\ttraining's binary_logloss: 0.219158\n",
      "[344]\ttraining's binary_logloss: 0.218994\n",
      "[345]\ttraining's binary_logloss: 0.218793\n",
      "[346]\ttraining's binary_logloss: 0.218565\n",
      "[347]\ttraining's binary_logloss: 0.218359\n",
      "[348]\ttraining's binary_logloss: 0.218268\n",
      "[349]\ttraining's binary_logloss: 0.218037\n",
      "[350]\ttraining's binary_logloss: 0.217856\n",
      "[351]\ttraining's binary_logloss: 0.217721\n",
      "[352]\ttraining's binary_logloss: 0.217557\n",
      "[353]\ttraining's binary_logloss: 0.217387\n",
      "[354]\ttraining's binary_logloss: 0.217158\n",
      "[355]\ttraining's binary_logloss: 0.216986\n",
      "[356]\ttraining's binary_logloss: 0.216848\n",
      "[357]\ttraining's binary_logloss: 0.216722\n",
      "[358]\ttraining's binary_logloss: 0.216597\n",
      "[359]\ttraining's binary_logloss: 0.21642\n",
      "[360]\ttraining's binary_logloss: 0.216257\n",
      "[361]\ttraining's binary_logloss: 0.216071\n",
      "[362]\ttraining's binary_logloss: 0.215904\n",
      "[363]\ttraining's binary_logloss: 0.215688\n",
      "[364]\ttraining's binary_logloss: 0.215513\n",
      "[365]\ttraining's binary_logloss: 0.21537\n",
      "[366]\ttraining's binary_logloss: 0.215171\n",
      "[367]\ttraining's binary_logloss: 0.215093\n",
      "[368]\ttraining's binary_logloss: 0.214874\n",
      "[369]\ttraining's binary_logloss: 0.214622\n",
      "[370]\ttraining's binary_logloss: 0.214436\n",
      "[371]\ttraining's binary_logloss: 0.214272\n",
      "[372]\ttraining's binary_logloss: 0.214077\n",
      "[373]\ttraining's binary_logloss: 0.213927\n",
      "[374]\ttraining's binary_logloss: 0.213781\n",
      "[375]\ttraining's binary_logloss: 0.213637\n",
      "[376]\ttraining's binary_logloss: 0.213441\n",
      "[377]\ttraining's binary_logloss: 0.213263\n",
      "[378]\ttraining's binary_logloss: 0.213056\n",
      "[379]\ttraining's binary_logloss: 0.21285\n",
      "[380]\ttraining's binary_logloss: 0.212675\n",
      "[381]\ttraining's binary_logloss: 0.21253\n",
      "[382]\ttraining's binary_logloss: 0.212334\n",
      "[383]\ttraining's binary_logloss: 0.212197\n",
      "[384]\ttraining's binary_logloss: 0.212046\n",
      "[385]\ttraining's binary_logloss: 0.21193\n",
      "[386]\ttraining's binary_logloss: 0.211837\n",
      "[387]\ttraining's binary_logloss: 0.211655\n",
      "[388]\ttraining's binary_logloss: 0.211463\n",
      "[389]\ttraining's binary_logloss: 0.211276\n",
      "[390]\ttraining's binary_logloss: 0.211074\n",
      "[391]\ttraining's binary_logloss: 0.210935\n",
      "[392]\ttraining's binary_logloss: 0.210829\n",
      "[393]\ttraining's binary_logloss: 0.210659\n",
      "[394]\ttraining's binary_logloss: 0.210488\n",
      "[395]\ttraining's binary_logloss: 0.210311\n",
      "[396]\ttraining's binary_logloss: 0.210187\n",
      "[397]\ttraining's binary_logloss: 0.210085\n",
      "[398]\ttraining's binary_logloss: 0.209935\n",
      "[399]\ttraining's binary_logloss: 0.209826\n",
      "[400]\ttraining's binary_logloss: 0.209622\n",
      "[401]\ttraining's binary_logloss: 0.209449\n",
      "[402]\ttraining's binary_logloss: 0.209285\n",
      "[403]\ttraining's binary_logloss: 0.209144\n",
      "[404]\ttraining's binary_logloss: 0.208986\n",
      "[405]\ttraining's binary_logloss: 0.208857\n",
      "[406]\ttraining's binary_logloss: 0.208663\n",
      "[407]\ttraining's binary_logloss: 0.208466\n",
      "[408]\ttraining's binary_logloss: 0.208332\n",
      "[409]\ttraining's binary_logloss: 0.20823\n",
      "[410]\ttraining's binary_logloss: 0.208054\n",
      "[411]\ttraining's binary_logloss: 0.207911\n",
      "[412]\ttraining's binary_logloss: 0.207826\n",
      "[413]\ttraining's binary_logloss: 0.207638\n",
      "[414]\ttraining's binary_logloss: 0.207488\n",
      "[415]\ttraining's binary_logloss: 0.207378\n",
      "[416]\ttraining's binary_logloss: 0.207238\n",
      "[417]\ttraining's binary_logloss: 0.207067\n",
      "[418]\ttraining's binary_logloss: 0.206898\n",
      "[419]\ttraining's binary_logloss: 0.206811\n",
      "[420]\ttraining's binary_logloss: 0.206668\n",
      "[421]\ttraining's binary_logloss: 0.206539\n",
      "[422]\ttraining's binary_logloss: 0.206397\n",
      "[423]\ttraining's binary_logloss: 0.206209\n",
      "[424]\ttraining's binary_logloss: 0.205984\n",
      "[425]\ttraining's binary_logloss: 0.205806\n",
      "[426]\ttraining's binary_logloss: 0.205574\n",
      "[427]\ttraining's binary_logloss: 0.205414\n",
      "[428]\ttraining's binary_logloss: 0.205256\n",
      "[429]\ttraining's binary_logloss: 0.205123\n",
      "[430]\ttraining's binary_logloss: 0.204965\n",
      "[431]\ttraining's binary_logloss: 0.204835\n",
      "[432]\ttraining's binary_logloss: 0.204727\n",
      "[433]\ttraining's binary_logloss: 0.204567\n",
      "[434]\ttraining's binary_logloss: 0.204377\n",
      "[435]\ttraining's binary_logloss: 0.204131\n",
      "[436]\ttraining's binary_logloss: 0.203993\n",
      "[437]\ttraining's binary_logloss: 0.203845\n",
      "[438]\ttraining's binary_logloss: 0.203675\n",
      "[439]\ttraining's binary_logloss: 0.203574\n",
      "[440]\ttraining's binary_logloss: 0.203409\n",
      "[441]\ttraining's binary_logloss: 0.203206\n",
      "[442]\ttraining's binary_logloss: 0.203084\n",
      "[443]\ttraining's binary_logloss: 0.202895\n",
      "[444]\ttraining's binary_logloss: 0.20278\n",
      "[445]\ttraining's binary_logloss: 0.202692\n",
      "[446]\ttraining's binary_logloss: 0.202537\n",
      "[447]\ttraining's binary_logloss: 0.202417\n",
      "[448]\ttraining's binary_logloss: 0.202234\n",
      "[449]\ttraining's binary_logloss: 0.202098\n",
      "[450]\ttraining's binary_logloss: 0.201921\n",
      "[451]\ttraining's binary_logloss: 0.201835\n",
      "[452]\ttraining's binary_logloss: 0.201611\n",
      "[453]\ttraining's binary_logloss: 0.201462\n",
      "[454]\ttraining's binary_logloss: 0.201341\n",
      "[455]\ttraining's binary_logloss: 0.201138\n",
      "[456]\ttraining's binary_logloss: 0.200955\n",
      "[457]\ttraining's binary_logloss: 0.200779\n",
      "[458]\ttraining's binary_logloss: 0.200681\n",
      "[459]\ttraining's binary_logloss: 0.200585\n",
      "[460]\ttraining's binary_logloss: 0.200406\n",
      "[461]\ttraining's binary_logloss: 0.200225\n",
      "[462]\ttraining's binary_logloss: 0.200063\n",
      "[463]\ttraining's binary_logloss: 0.199905\n",
      "[464]\ttraining's binary_logloss: 0.199739\n",
      "[465]\ttraining's binary_logloss: 0.199549\n",
      "[466]\ttraining's binary_logloss: 0.199451\n",
      "[467]\ttraining's binary_logloss: 0.199277\n",
      "[468]\ttraining's binary_logloss: 0.199181\n",
      "[469]\ttraining's binary_logloss: 0.199048\n",
      "[470]\ttraining's binary_logloss: 0.198939\n",
      "[471]\ttraining's binary_logloss: 0.198786\n",
      "[472]\ttraining's binary_logloss: 0.198626\n",
      "[473]\ttraining's binary_logloss: 0.198523\n",
      "[474]\ttraining's binary_logloss: 0.198336\n",
      "[475]\ttraining's binary_logloss: 0.198172\n",
      "[476]\ttraining's binary_logloss: 0.198024\n",
      "[477]\ttraining's binary_logloss: 0.197851\n",
      "[478]\ttraining's binary_logloss: 0.197724\n",
      "[479]\ttraining's binary_logloss: 0.197542\n",
      "[480]\ttraining's binary_logloss: 0.197368\n",
      "[481]\ttraining's binary_logloss: 0.19722\n",
      "[482]\ttraining's binary_logloss: 0.197048\n",
      "[483]\ttraining's binary_logloss: 0.19692\n",
      "[484]\ttraining's binary_logloss: 0.196753\n",
      "[485]\ttraining's binary_logloss: 0.19657\n",
      "[486]\ttraining's binary_logloss: 0.196459\n",
      "[487]\ttraining's binary_logloss: 0.196323\n",
      "[488]\ttraining's binary_logloss: 0.196221\n",
      "[489]\ttraining's binary_logloss: 0.196037\n",
      "[490]\ttraining's binary_logloss: 0.195843\n",
      "[491]\ttraining's binary_logloss: 0.195734\n",
      "[492]\ttraining's binary_logloss: 0.195629\n",
      "[493]\ttraining's binary_logloss: 0.195476\n",
      "[494]\ttraining's binary_logloss: 0.195366\n",
      "[495]\ttraining's binary_logloss: 0.195171\n",
      "[496]\ttraining's binary_logloss: 0.194964\n",
      "[497]\ttraining's binary_logloss: 0.194829\n",
      "[498]\ttraining's binary_logloss: 0.194762\n",
      "[499]\ttraining's binary_logloss: 0.194577\n",
      "[500]\ttraining's binary_logloss: 0.194493\n",
      "[501]\ttraining's binary_logloss: 0.194389\n",
      "[502]\ttraining's binary_logloss: 0.1943\n",
      "[503]\ttraining's binary_logloss: 0.194124\n",
      "[504]\ttraining's binary_logloss: 0.193974\n",
      "[505]\ttraining's binary_logloss: 0.193898\n",
      "[506]\ttraining's binary_logloss: 0.193743\n",
      "[507]\ttraining's binary_logloss: 0.193562\n",
      "[508]\ttraining's binary_logloss: 0.193393\n",
      "[509]\ttraining's binary_logloss: 0.193232\n",
      "[510]\ttraining's binary_logloss: 0.193055\n",
      "[511]\ttraining's binary_logloss: 0.192941\n",
      "[512]\ttraining's binary_logloss: 0.192782\n",
      "[513]\ttraining's binary_logloss: 0.192578\n",
      "[514]\ttraining's binary_logloss: 0.192447\n",
      "[515]\ttraining's binary_logloss: 0.192339\n",
      "[516]\ttraining's binary_logloss: 0.192207\n",
      "[517]\ttraining's binary_logloss: 0.192044\n",
      "[518]\ttraining's binary_logloss: 0.191927\n",
      "[519]\ttraining's binary_logloss: 0.191752\n",
      "[520]\ttraining's binary_logloss: 0.191574\n",
      "[521]\ttraining's binary_logloss: 0.191399\n",
      "[522]\ttraining's binary_logloss: 0.191235\n",
      "[523]\ttraining's binary_logloss: 0.191107\n",
      "[524]\ttraining's binary_logloss: 0.19098\n",
      "[525]\ttraining's binary_logloss: 0.19083\n",
      "[526]\ttraining's binary_logloss: 0.190716\n",
      "[527]\ttraining's binary_logloss: 0.190575\n",
      "[528]\ttraining's binary_logloss: 0.190411\n",
      "[529]\ttraining's binary_logloss: 0.190253\n",
      "[530]\ttraining's binary_logloss: 0.19018\n",
      "[531]\ttraining's binary_logloss: 0.19002\n",
      "[532]\ttraining's binary_logloss: 0.189874\n",
      "[533]\ttraining's binary_logloss: 0.189677\n",
      "[534]\ttraining's binary_logloss: 0.189508\n",
      "[535]\ttraining's binary_logloss: 0.18936\n",
      "[536]\ttraining's binary_logloss: 0.189176\n",
      "[537]\ttraining's binary_logloss: 0.189092\n",
      "[538]\ttraining's binary_logloss: 0.188934\n",
      "[539]\ttraining's binary_logloss: 0.188779\n",
      "[540]\ttraining's binary_logloss: 0.188597\n",
      "[541]\ttraining's binary_logloss: 0.188503\n",
      "[542]\ttraining's binary_logloss: 0.188375\n",
      "[543]\ttraining's binary_logloss: 0.188236\n",
      "[544]\ttraining's binary_logloss: 0.188094\n",
      "[545]\ttraining's binary_logloss: 0.188\n",
      "[546]\ttraining's binary_logloss: 0.187924\n",
      "[547]\ttraining's binary_logloss: 0.187797\n",
      "[548]\ttraining's binary_logloss: 0.187647\n",
      "[549]\ttraining's binary_logloss: 0.187465\n",
      "[550]\ttraining's binary_logloss: 0.187347\n",
      "[551]\ttraining's binary_logloss: 0.187185\n",
      "[552]\ttraining's binary_logloss: 0.187039\n",
      "[553]\ttraining's binary_logloss: 0.186909\n",
      "[554]\ttraining's binary_logloss: 0.186732\n",
      "[555]\ttraining's binary_logloss: 0.186647\n",
      "[556]\ttraining's binary_logloss: 0.186579\n",
      "[557]\ttraining's binary_logloss: 0.186414\n",
      "[558]\ttraining's binary_logloss: 0.186256\n",
      "[559]\ttraining's binary_logloss: 0.18615\n",
      "[560]\ttraining's binary_logloss: 0.186065\n",
      "[561]\ttraining's binary_logloss: 0.185938\n",
      "[562]\ttraining's binary_logloss: 0.185822\n",
      "[563]\ttraining's binary_logloss: 0.185657\n",
      "[564]\ttraining's binary_logloss: 0.185544\n",
      "[565]\ttraining's binary_logloss: 0.185348\n",
      "[566]\ttraining's binary_logloss: 0.185192\n",
      "[567]\ttraining's binary_logloss: 0.18504\n",
      "[568]\ttraining's binary_logloss: 0.184906\n",
      "[569]\ttraining's binary_logloss: 0.184829\n",
      "[570]\ttraining's binary_logloss: 0.184677\n",
      "[571]\ttraining's binary_logloss: 0.184498\n",
      "[572]\ttraining's binary_logloss: 0.184327\n",
      "[573]\ttraining's binary_logloss: 0.184223\n",
      "[574]\ttraining's binary_logloss: 0.184146\n",
      "[575]\ttraining's binary_logloss: 0.183985\n",
      "[576]\ttraining's binary_logloss: 0.183827\n",
      "[577]\ttraining's binary_logloss: 0.183682\n",
      "[578]\ttraining's binary_logloss: 0.183564\n",
      "[579]\ttraining's binary_logloss: 0.183405\n",
      "[580]\ttraining's binary_logloss: 0.183264\n",
      "[581]\ttraining's binary_logloss: 0.183122\n",
      "[582]\ttraining's binary_logloss: 0.182957\n",
      "[583]\ttraining's binary_logloss: 0.182857\n",
      "[584]\ttraining's binary_logloss: 0.182722\n",
      "[585]\ttraining's binary_logloss: 0.182547\n",
      "[586]\ttraining's binary_logloss: 0.182392\n",
      "[587]\ttraining's binary_logloss: 0.182255\n",
      "[588]\ttraining's binary_logloss: 0.182074\n",
      "[589]\ttraining's binary_logloss: 0.18193\n",
      "[590]\ttraining's binary_logloss: 0.181785\n",
      "[591]\ttraining's binary_logloss: 0.181634\n",
      "[592]\ttraining's binary_logloss: 0.18148\n",
      "[593]\ttraining's binary_logloss: 0.181391\n",
      "[594]\ttraining's binary_logloss: 0.181258\n",
      "[595]\ttraining's binary_logloss: 0.181175\n",
      "[596]\ttraining's binary_logloss: 0.181008\n",
      "[597]\ttraining's binary_logloss: 0.180839\n",
      "[598]\ttraining's binary_logloss: 0.180672\n",
      "[599]\ttraining's binary_logloss: 0.180594\n",
      "[600]\ttraining's binary_logloss: 0.180467\n",
      "[601]\ttraining's binary_logloss: 0.180378\n",
      "[602]\ttraining's binary_logloss: 0.180242\n",
      "[603]\ttraining's binary_logloss: 0.180104\n",
      "[604]\ttraining's binary_logloss: 0.179951\n",
      "[605]\ttraining's binary_logloss: 0.17986\n",
      "[606]\ttraining's binary_logloss: 0.179757\n",
      "[607]\ttraining's binary_logloss: 0.179641\n",
      "[608]\ttraining's binary_logloss: 0.179488\n",
      "[609]\ttraining's binary_logloss: 0.179366\n",
      "[610]\ttraining's binary_logloss: 0.1792\n",
      "[611]\ttraining's binary_logloss: 0.179013\n",
      "[612]\ttraining's binary_logloss: 0.178854\n",
      "[613]\ttraining's binary_logloss: 0.178718\n",
      "[614]\ttraining's binary_logloss: 0.178578\n",
      "[615]\ttraining's binary_logloss: 0.178371\n",
      "[616]\ttraining's binary_logloss: 0.17822\n",
      "[617]\ttraining's binary_logloss: 0.178093\n",
      "[618]\ttraining's binary_logloss: 0.177942\n",
      "[619]\ttraining's binary_logloss: 0.177777\n",
      "[620]\ttraining's binary_logloss: 0.177681\n",
      "[621]\ttraining's binary_logloss: 0.177594\n",
      "[622]\ttraining's binary_logloss: 0.177522\n",
      "[623]\ttraining's binary_logloss: 0.177408\n",
      "[624]\ttraining's binary_logloss: 0.177327\n",
      "[625]\ttraining's binary_logloss: 0.17724\n",
      "[626]\ttraining's binary_logloss: 0.177135\n",
      "[627]\ttraining's binary_logloss: 0.176989\n",
      "[628]\ttraining's binary_logloss: 0.176851\n",
      "[629]\ttraining's binary_logloss: 0.176689\n",
      "[630]\ttraining's binary_logloss: 0.176607\n",
      "[631]\ttraining's binary_logloss: 0.176464\n",
      "[632]\ttraining's binary_logloss: 0.176359\n",
      "[633]\ttraining's binary_logloss: 0.176207\n",
      "[634]\ttraining's binary_logloss: 0.176116\n",
      "[635]\ttraining's binary_logloss: 0.175949\n",
      "[636]\ttraining's binary_logloss: 0.175792\n",
      "[637]\ttraining's binary_logloss: 0.175671\n",
      "[638]\ttraining's binary_logloss: 0.175605\n",
      "[639]\ttraining's binary_logloss: 0.175487\n",
      "[640]\ttraining's binary_logloss: 0.17536\n",
      "[641]\ttraining's binary_logloss: 0.17524\n",
      "[642]\ttraining's binary_logloss: 0.175105\n",
      "[643]\ttraining's binary_logloss: 0.175003\n",
      "[644]\ttraining's binary_logloss: 0.17494\n",
      "[645]\ttraining's binary_logloss: 0.174816\n",
      "[646]\ttraining's binary_logloss: 0.174708\n",
      "[647]\ttraining's binary_logloss: 0.174569\n",
      "[648]\ttraining's binary_logloss: 0.174434\n",
      "[649]\ttraining's binary_logloss: 0.174331\n",
      "[650]\ttraining's binary_logloss: 0.174214\n",
      "[651]\ttraining's binary_logloss: 0.174046\n",
      "[652]\ttraining's binary_logloss: 0.173909\n",
      "[653]\ttraining's binary_logloss: 0.173776\n",
      "[654]\ttraining's binary_logloss: 0.173673\n",
      "[655]\ttraining's binary_logloss: 0.173527\n",
      "[656]\ttraining's binary_logloss: 0.173391\n",
      "[657]\ttraining's binary_logloss: 0.173289\n",
      "[658]\ttraining's binary_logloss: 0.173141\n",
      "[659]\ttraining's binary_logloss: 0.173055\n",
      "[660]\ttraining's binary_logloss: 0.17294\n",
      "[661]\ttraining's binary_logloss: 0.172844\n",
      "[662]\ttraining's binary_logloss: 0.1727\n",
      "[663]\ttraining's binary_logloss: 0.172575\n",
      "[664]\ttraining's binary_logloss: 0.172433\n",
      "[665]\ttraining's binary_logloss: 0.172295\n",
      "[666]\ttraining's binary_logloss: 0.172142\n",
      "[667]\ttraining's binary_logloss: 0.172012\n",
      "[668]\ttraining's binary_logloss: 0.171943\n",
      "[669]\ttraining's binary_logloss: 0.171881\n",
      "[670]\ttraining's binary_logloss: 0.171743\n",
      "[671]\ttraining's binary_logloss: 0.171618\n",
      "[672]\ttraining's binary_logloss: 0.171487\n",
      "[673]\ttraining's binary_logloss: 0.171342\n",
      "[674]\ttraining's binary_logloss: 0.171211\n",
      "[675]\ttraining's binary_logloss: 0.171071\n",
      "[676]\ttraining's binary_logloss: 0.170954\n",
      "[677]\ttraining's binary_logloss: 0.170807\n",
      "[678]\ttraining's binary_logloss: 0.170662\n",
      "[679]\ttraining's binary_logloss: 0.170534\n",
      "[680]\ttraining's binary_logloss: 0.170377\n",
      "[681]\ttraining's binary_logloss: 0.170262\n",
      "[682]\ttraining's binary_logloss: 0.170135\n",
      "[683]\ttraining's binary_logloss: 0.169981\n",
      "[684]\ttraining's binary_logloss: 0.169906\n",
      "[685]\ttraining's binary_logloss: 0.169784\n",
      "[686]\ttraining's binary_logloss: 0.169688\n",
      "[687]\ttraining's binary_logloss: 0.169594\n",
      "[688]\ttraining's binary_logloss: 0.169446\n",
      "[689]\ttraining's binary_logloss: 0.169335\n",
      "[690]\ttraining's binary_logloss: 0.169155\n",
      "[691]\ttraining's binary_logloss: 0.169008\n",
      "[692]\ttraining's binary_logloss: 0.168937\n",
      "[693]\ttraining's binary_logloss: 0.1688\n",
      "[694]\ttraining's binary_logloss: 0.168699\n",
      "[695]\ttraining's binary_logloss: 0.168549\n",
      "[696]\ttraining's binary_logloss: 0.168384\n",
      "[697]\ttraining's binary_logloss: 0.168249\n",
      "[698]\ttraining's binary_logloss: 0.168157\n",
      "[699]\ttraining's binary_logloss: 0.168023\n",
      "[700]\ttraining's binary_logloss: 0.167877\n",
      "[701]\ttraining's binary_logloss: 0.167708\n",
      "[702]\ttraining's binary_logloss: 0.167601\n",
      "[703]\ttraining's binary_logloss: 0.167519\n",
      "[704]\ttraining's binary_logloss: 0.167385\n",
      "[705]\ttraining's binary_logloss: 0.167317\n",
      "[706]\ttraining's binary_logloss: 0.167245\n",
      "[707]\ttraining's binary_logloss: 0.16709\n",
      "[708]\ttraining's binary_logloss: 0.166993\n",
      "[709]\ttraining's binary_logloss: 0.166857\n",
      "[710]\ttraining's binary_logloss: 0.166781\n",
      "[711]\ttraining's binary_logloss: 0.166631\n",
      "[712]\ttraining's binary_logloss: 0.166494\n",
      "[713]\ttraining's binary_logloss: 0.166345\n",
      "[714]\ttraining's binary_logloss: 0.166278\n",
      "[715]\ttraining's binary_logloss: 0.166182\n",
      "[716]\ttraining's binary_logloss: 0.166048\n",
      "[717]\ttraining's binary_logloss: 0.165921\n",
      "[718]\ttraining's binary_logloss: 0.1658\n",
      "[719]\ttraining's binary_logloss: 0.165718\n",
      "[720]\ttraining's binary_logloss: 0.165611\n",
      "[721]\ttraining's binary_logloss: 0.165476\n",
      "[722]\ttraining's binary_logloss: 0.16531\n",
      "[723]\ttraining's binary_logloss: 0.165177\n",
      "[724]\ttraining's binary_logloss: 0.165024\n",
      "[725]\ttraining's binary_logloss: 0.164878\n",
      "[726]\ttraining's binary_logloss: 0.16477\n",
      "[727]\ttraining's binary_logloss: 0.164655\n",
      "[728]\ttraining's binary_logloss: 0.164519\n",
      "[729]\ttraining's binary_logloss: 0.164427\n",
      "[730]\ttraining's binary_logloss: 0.164354\n",
      "[731]\ttraining's binary_logloss: 0.164272\n",
      "[732]\ttraining's binary_logloss: 0.164116\n",
      "[733]\ttraining's binary_logloss: 0.16403\n",
      "[734]\ttraining's binary_logloss: 0.163914\n",
      "[735]\ttraining's binary_logloss: 0.163774\n",
      "[736]\ttraining's binary_logloss: 0.163658\n",
      "[737]\ttraining's binary_logloss: 0.16351\n",
      "[738]\ttraining's binary_logloss: 0.16342\n",
      "[739]\ttraining's binary_logloss: 0.163248\n",
      "[740]\ttraining's binary_logloss: 0.163147\n",
      "[741]\ttraining's binary_logloss: 0.163083\n",
      "[742]\ttraining's binary_logloss: 0.162941\n",
      "[743]\ttraining's binary_logloss: 0.162807\n",
      "[744]\ttraining's binary_logloss: 0.162705\n",
      "[745]\ttraining's binary_logloss: 0.162577\n",
      "[746]\ttraining's binary_logloss: 0.162457\n",
      "[747]\ttraining's binary_logloss: 0.16234\n",
      "[748]\ttraining's binary_logloss: 0.162224\n",
      "[749]\ttraining's binary_logloss: 0.162088\n",
      "[750]\ttraining's binary_logloss: 0.161983\n",
      "[751]\ttraining's binary_logloss: 0.161851\n",
      "[752]\ttraining's binary_logloss: 0.161731\n",
      "[753]\ttraining's binary_logloss: 0.161648\n",
      "[754]\ttraining's binary_logloss: 0.161516\n",
      "[755]\ttraining's binary_logloss: 0.161403\n",
      "[756]\ttraining's binary_logloss: 0.161338\n",
      "[757]\ttraining's binary_logloss: 0.161266\n",
      "[758]\ttraining's binary_logloss: 0.161199\n",
      "[759]\ttraining's binary_logloss: 0.161083\n",
      "[760]\ttraining's binary_logloss: 0.160936\n",
      "[761]\ttraining's binary_logloss: 0.160815\n",
      "[762]\ttraining's binary_logloss: 0.160699\n",
      "[763]\ttraining's binary_logloss: 0.160594\n",
      "[764]\ttraining's binary_logloss: 0.160464\n",
      "[765]\ttraining's binary_logloss: 0.160352\n",
      "[766]\ttraining's binary_logloss: 0.160221\n",
      "[767]\ttraining's binary_logloss: 0.160154\n",
      "[768]\ttraining's binary_logloss: 0.160036\n",
      "[769]\ttraining's binary_logloss: 0.159898\n",
      "[770]\ttraining's binary_logloss: 0.159738\n",
      "[771]\ttraining's binary_logloss: 0.159615\n",
      "[772]\ttraining's binary_logloss: 0.15947\n",
      "[773]\ttraining's binary_logloss: 0.159315\n",
      "[774]\ttraining's binary_logloss: 0.159205\n",
      "[775]\ttraining's binary_logloss: 0.15905\n",
      "[776]\ttraining's binary_logloss: 0.158958\n",
      "[777]\ttraining's binary_logloss: 0.158838\n",
      "[778]\ttraining's binary_logloss: 0.158712\n",
      "[779]\ttraining's binary_logloss: 0.158564\n",
      "[780]\ttraining's binary_logloss: 0.158483\n",
      "[781]\ttraining's binary_logloss: 0.158415\n",
      "[782]\ttraining's binary_logloss: 0.158297\n",
      "[783]\ttraining's binary_logloss: 0.158192\n",
      "[784]\ttraining's binary_logloss: 0.15805\n",
      "[785]\ttraining's binary_logloss: 0.157923\n",
      "[786]\ttraining's binary_logloss: 0.157789\n",
      "[787]\ttraining's binary_logloss: 0.157682\n",
      "[788]\ttraining's binary_logloss: 0.157577\n",
      "[789]\ttraining's binary_logloss: 0.157496\n",
      "[790]\ttraining's binary_logloss: 0.157393\n",
      "[791]\ttraining's binary_logloss: 0.157286\n",
      "[792]\ttraining's binary_logloss: 0.157141\n",
      "[793]\ttraining's binary_logloss: 0.15701\n",
      "[794]\ttraining's binary_logloss: 0.156878\n",
      "[795]\ttraining's binary_logloss: 0.156759\n",
      "[796]\ttraining's binary_logloss: 0.156624\n",
      "[797]\ttraining's binary_logloss: 0.156446\n",
      "[798]\ttraining's binary_logloss: 0.156337\n",
      "[799]\ttraining's binary_logloss: 0.156238\n",
      "[800]\ttraining's binary_logloss: 0.156093\n",
      "[801]\ttraining's binary_logloss: 0.155965\n",
      "[802]\ttraining's binary_logloss: 0.155891\n",
      "[803]\ttraining's binary_logloss: 0.155763\n",
      "[804]\ttraining's binary_logloss: 0.155705\n",
      "[805]\ttraining's binary_logloss: 0.155609\n",
      "[806]\ttraining's binary_logloss: 0.155467\n",
      "[807]\ttraining's binary_logloss: 0.155351\n",
      "[808]\ttraining's binary_logloss: 0.155272\n",
      "[809]\ttraining's binary_logloss: 0.155149\n",
      "[810]\ttraining's binary_logloss: 0.154995\n",
      "[811]\ttraining's binary_logloss: 0.154898\n",
      "[812]\ttraining's binary_logloss: 0.15478\n",
      "[813]\ttraining's binary_logloss: 0.154716\n",
      "[814]\ttraining's binary_logloss: 0.154592\n",
      "[815]\ttraining's binary_logloss: 0.154473\n",
      "[816]\ttraining's binary_logloss: 0.15435\n",
      "[817]\ttraining's binary_logloss: 0.154297\n",
      "[818]\ttraining's binary_logloss: 0.15414\n",
      "[819]\ttraining's binary_logloss: 0.15402\n",
      "[820]\ttraining's binary_logloss: 0.153965\n",
      "[821]\ttraining's binary_logloss: 0.153869\n",
      "[822]\ttraining's binary_logloss: 0.153735\n",
      "[823]\ttraining's binary_logloss: 0.153617\n",
      "[824]\ttraining's binary_logloss: 0.153494\n",
      "[825]\ttraining's binary_logloss: 0.15338\n",
      "[826]\ttraining's binary_logloss: 0.153321\n",
      "[827]\ttraining's binary_logloss: 0.153178\n",
      "[828]\ttraining's binary_logloss: 0.153038\n",
      "[829]\ttraining's binary_logloss: 0.152935\n",
      "[830]\ttraining's binary_logloss: 0.152789\n",
      "[831]\ttraining's binary_logloss: 0.152677\n",
      "[832]\ttraining's binary_logloss: 0.152557\n",
      "[833]\ttraining's binary_logloss: 0.152457\n",
      "[834]\ttraining's binary_logloss: 0.152355\n",
      "[835]\ttraining's binary_logloss: 0.152212\n",
      "[836]\ttraining's binary_logloss: 0.15209\n",
      "[837]\ttraining's binary_logloss: 0.151994\n",
      "[838]\ttraining's binary_logloss: 0.151865\n",
      "[839]\ttraining's binary_logloss: 0.151765\n",
      "[840]\ttraining's binary_logloss: 0.151639\n",
      "[841]\ttraining's binary_logloss: 0.151557\n",
      "[842]\ttraining's binary_logloss: 0.151445\n",
      "[843]\ttraining's binary_logloss: 0.15134\n",
      "[844]\ttraining's binary_logloss: 0.151237\n",
      "[845]\ttraining's binary_logloss: 0.1511\n",
      "[846]\ttraining's binary_logloss: 0.150979\n",
      "[847]\ttraining's binary_logloss: 0.150847\n",
      "[848]\ttraining's binary_logloss: 0.150739\n",
      "[849]\ttraining's binary_logloss: 0.150651\n",
      "[850]\ttraining's binary_logloss: 0.15054\n",
      "[851]\ttraining's binary_logloss: 0.15042\n",
      "[852]\ttraining's binary_logloss: 0.150319\n",
      "[853]\ttraining's binary_logloss: 0.15022\n",
      "[854]\ttraining's binary_logloss: 0.150115\n",
      "[855]\ttraining's binary_logloss: 0.149976\n",
      "[856]\ttraining's binary_logloss: 0.149851\n",
      "[857]\ttraining's binary_logloss: 0.149781\n",
      "[858]\ttraining's binary_logloss: 0.149648\n",
      "[859]\ttraining's binary_logloss: 0.149527\n",
      "[860]\ttraining's binary_logloss: 0.149408\n",
      "[861]\ttraining's binary_logloss: 0.149315\n",
      "[862]\ttraining's binary_logloss: 0.14926\n",
      "[863]\ttraining's binary_logloss: 0.149129\n",
      "[864]\ttraining's binary_logloss: 0.149026\n",
      "[865]\ttraining's binary_logloss: 0.148914\n",
      "[866]\ttraining's binary_logloss: 0.148797\n",
      "[867]\ttraining's binary_logloss: 0.148682\n",
      "[868]\ttraining's binary_logloss: 0.148615\n",
      "[869]\ttraining's binary_logloss: 0.1485\n",
      "[870]\ttraining's binary_logloss: 0.14837\n",
      "[871]\ttraining's binary_logloss: 0.148279\n",
      "[872]\ttraining's binary_logloss: 0.148173\n",
      "[873]\ttraining's binary_logloss: 0.148054\n",
      "[874]\ttraining's binary_logloss: 0.147945\n",
      "[875]\ttraining's binary_logloss: 0.147872\n",
      "[876]\ttraining's binary_logloss: 0.147767\n",
      "[877]\ttraining's binary_logloss: 0.147634\n",
      "[878]\ttraining's binary_logloss: 0.147528\n",
      "[879]\ttraining's binary_logloss: 0.147396\n",
      "[880]\ttraining's binary_logloss: 0.147326\n",
      "[881]\ttraining's binary_logloss: 0.147205\n",
      "[882]\ttraining's binary_logloss: 0.147078\n",
      "[883]\ttraining's binary_logloss: 0.146948\n",
      "[884]\ttraining's binary_logloss: 0.146827\n",
      "[885]\ttraining's binary_logloss: 0.146772\n",
      "[886]\ttraining's binary_logloss: 0.146683\n",
      "[887]\ttraining's binary_logloss: 0.14663\n",
      "[888]\ttraining's binary_logloss: 0.146539\n",
      "[889]\ttraining's binary_logloss: 0.146415\n",
      "[890]\ttraining's binary_logloss: 0.146314\n",
      "[891]\ttraining's binary_logloss: 0.146218\n",
      "[892]\ttraining's binary_logloss: 0.146099\n",
      "[893]\ttraining's binary_logloss: 0.145986\n",
      "[894]\ttraining's binary_logloss: 0.145846\n",
      "[895]\ttraining's binary_logloss: 0.145798\n",
      "[896]\ttraining's binary_logloss: 0.145737\n",
      "[897]\ttraining's binary_logloss: 0.145613\n",
      "[898]\ttraining's binary_logloss: 0.145491\n",
      "[899]\ttraining's binary_logloss: 0.14541\n",
      "[900]\ttraining's binary_logloss: 0.14533\n",
      "[901]\ttraining's binary_logloss: 0.145208\n",
      "[902]\ttraining's binary_logloss: 0.145113\n",
      "[903]\ttraining's binary_logloss: 0.145009\n",
      "[904]\ttraining's binary_logloss: 0.144911\n",
      "[905]\ttraining's binary_logloss: 0.144818\n",
      "[906]\ttraining's binary_logloss: 0.144697\n",
      "[907]\ttraining's binary_logloss: 0.144657\n",
      "[908]\ttraining's binary_logloss: 0.144543\n",
      "[909]\ttraining's binary_logloss: 0.144434\n",
      "[910]\ttraining's binary_logloss: 0.144297\n",
      "[911]\ttraining's binary_logloss: 0.144173\n",
      "[912]\ttraining's binary_logloss: 0.144069\n",
      "[913]\ttraining's binary_logloss: 0.144015\n",
      "[914]\ttraining's binary_logloss: 0.143924\n",
      "[915]\ttraining's binary_logloss: 0.143831\n",
      "[916]\ttraining's binary_logloss: 0.143704\n",
      "[917]\ttraining's binary_logloss: 0.14362\n",
      "[918]\ttraining's binary_logloss: 0.143506\n",
      "[919]\ttraining's binary_logloss: 0.143385\n",
      "[920]\ttraining's binary_logloss: 0.143306\n",
      "[921]\ttraining's binary_logloss: 0.143253\n",
      "[922]\ttraining's binary_logloss: 0.143144\n",
      "[923]\ttraining's binary_logloss: 0.143035\n",
      "[924]\ttraining's binary_logloss: 0.142961\n",
      "[925]\ttraining's binary_logloss: 0.14284\n",
      "[926]\ttraining's binary_logloss: 0.142758\n",
      "[927]\ttraining's binary_logloss: 0.142633\n",
      "[928]\ttraining's binary_logloss: 0.142512\n",
      "[929]\ttraining's binary_logloss: 0.142359\n",
      "[930]\ttraining's binary_logloss: 0.142286\n",
      "[931]\ttraining's binary_logloss: 0.142196\n",
      "[932]\ttraining's binary_logloss: 0.142075\n",
      "[933]\ttraining's binary_logloss: 0.141976\n",
      "[934]\ttraining's binary_logloss: 0.141862\n",
      "[935]\ttraining's binary_logloss: 0.141754\n",
      "[936]\ttraining's binary_logloss: 0.141653\n",
      "[937]\ttraining's binary_logloss: 0.14156\n",
      "[938]\ttraining's binary_logloss: 0.141479\n",
      "[939]\ttraining's binary_logloss: 0.141404\n",
      "[940]\ttraining's binary_logloss: 0.141285\n",
      "[941]\ttraining's binary_logloss: 0.141142\n",
      "[942]\ttraining's binary_logloss: 0.141034\n",
      "[943]\ttraining's binary_logloss: 0.140959\n",
      "[944]\ttraining's binary_logloss: 0.140865\n",
      "[945]\ttraining's binary_logloss: 0.140787\n",
      "[946]\ttraining's binary_logloss: 0.140702\n",
      "[947]\ttraining's binary_logloss: 0.140657\n",
      "[948]\ttraining's binary_logloss: 0.140604\n",
      "[949]\ttraining's binary_logloss: 0.140546\n",
      "[950]\ttraining's binary_logloss: 0.140419\n",
      "[951]\ttraining's binary_logloss: 0.140312\n",
      "[952]\ttraining's binary_logloss: 0.140191\n",
      "[953]\ttraining's binary_logloss: 0.140128\n",
      "[954]\ttraining's binary_logloss: 0.140021\n",
      "[955]\ttraining's binary_logloss: 0.139917\n",
      "[956]\ttraining's binary_logloss: 0.139826\n",
      "[957]\ttraining's binary_logloss: 0.139706\n",
      "[958]\ttraining's binary_logloss: 0.139582\n",
      "[959]\ttraining's binary_logloss: 0.139472\n",
      "[960]\ttraining's binary_logloss: 0.139389\n",
      "[961]\ttraining's binary_logloss: 0.139314\n",
      "[962]\ttraining's binary_logloss: 0.139248\n",
      "[963]\ttraining's binary_logloss: 0.139149\n",
      "[964]\ttraining's binary_logloss: 0.139037\n",
      "[965]\ttraining's binary_logloss: 0.138903\n",
      "[966]\ttraining's binary_logloss: 0.138794\n",
      "[967]\ttraining's binary_logloss: 0.138702\n",
      "[968]\ttraining's binary_logloss: 0.138576\n",
      "[969]\ttraining's binary_logloss: 0.138484\n",
      "[970]\ttraining's binary_logloss: 0.138383\n",
      "[971]\ttraining's binary_logloss: 0.138265\n",
      "[972]\ttraining's binary_logloss: 0.13817\n",
      "[973]\ttraining's binary_logloss: 0.138052\n",
      "[974]\ttraining's binary_logloss: 0.13798\n",
      "[975]\ttraining's binary_logloss: 0.137881\n",
      "[976]\ttraining's binary_logloss: 0.137822\n",
      "[977]\ttraining's binary_logloss: 0.13769\n",
      "[978]\ttraining's binary_logloss: 0.137561\n",
      "[979]\ttraining's binary_logloss: 0.137465\n",
      "[980]\ttraining's binary_logloss: 0.137371\n",
      "[981]\ttraining's binary_logloss: 0.137244\n",
      "[982]\ttraining's binary_logloss: 0.137135\n",
      "[983]\ttraining's binary_logloss: 0.137051\n",
      "[984]\ttraining's binary_logloss: 0.136913\n",
      "[985]\ttraining's binary_logloss: 0.1368\n",
      "[986]\ttraining's binary_logloss: 0.1367\n",
      "[987]\ttraining's binary_logloss: 0.136597\n",
      "[988]\ttraining's binary_logloss: 0.136429\n",
      "[989]\ttraining's binary_logloss: 0.136333\n",
      "[990]\ttraining's binary_logloss: 0.136235\n",
      "[991]\ttraining's binary_logloss: 0.136174\n",
      "[992]\ttraining's binary_logloss: 0.136079\n",
      "[993]\ttraining's binary_logloss: 0.135993\n",
      "[994]\ttraining's binary_logloss: 0.135914\n",
      "[995]\ttraining's binary_logloss: 0.135805\n",
      "[996]\ttraining's binary_logloss: 0.135695\n",
      "[997]\ttraining's binary_logloss: 0.135631\n",
      "[998]\ttraining's binary_logloss: 0.135553\n",
      "[999]\ttraining's binary_logloss: 0.135426\n",
      "[1000]\ttraining's binary_logloss: 0.135346\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     'boosting_type': 'dart', #gbdt\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'binary_logloss',\n",
    "#     'num_leaves': 11,\n",
    "#     'learning_rate': 0.05,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'bagging_freq': 5,\n",
    "#     'verbose': 0\n",
    "# }\n",
    "params = { 'boosting_type': 'gbdt', 'objective': 'binary','metric': 'binary_logloss',\n",
    "'bagging_fraction': 1.0, 'colsample_bytree': 1.0, 'feature_fraction': 1.0, 'max_depth': 11, \n",
    "          'min_child_weight': 0.001, 'min_split_gain': 0.10000000000000001, 'n_estimators': 259, 'subsample': 1.0}\n",
    "\n",
    "boost_rounds_form = 1000\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "lgb_train_form = lgb.Dataset(X_train, y_train)\n",
    "gbm_form = lgb.train(\n",
    "                params,\n",
    "                lgb_train_form,\n",
    "                valid_sets=lgb_train_form,\n",
    "                num_boost_round=boost_rounds_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbm_form.predict(data=X_test, raw_score=True)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(0,len(preds)):\n",
    "    if preds[i]>=.5:       # setting threshold to .5\n",
    "        preds[i]=1\n",
    "    else:  \n",
    "        preds[i]=0\n",
    "preds\n",
    "\n",
    "confusion_matrix =confusion_matrix(y_test, preds)\n",
    "confusion_matrix\n",
    "list1 = [\"Actual Survived\", \"Actual Died\"]\n",
    "list2 = [\"Predicted Survived\", \"Predicted Died\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Survived</th>\n",
       "      <th>Predicted Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Survived</th>\n",
       "      <td>34811</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Died</th>\n",
       "      <td>4876</td>\n",
       "      <td>6259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Survived  Predicted Died\n",
       "Actual Survived               34811            1458\n",
       "Actual Died                    4876            6259"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix, list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86638258374820687"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, 'num_prev_tx'),\n",
       " (1, 'donation'),\n",
       " (77, 'on_dialysis'),\n",
       " (227, 'a1'),\n",
       " (417, 'a2'),\n",
       " (371, 'b1'),\n",
       " (470, 'b2'),\n",
       " (303, 'dr1'),\n",
       " (348, 'dr2'),\n",
       " (45, 'gender'),\n",
       " (130, 'abo'),\n",
       " (498, 'wgt_kg_tcr'),\n",
       " (318, 'hgt_cm_tcr'),\n",
       " (561, 'bmi_tcr'),\n",
       " (787, 'perm_state'),\n",
       " (278, 'education'),\n",
       " (209, 'func_stat_tcr'),\n",
       " (551, 'dgn_tcr'),\n",
       " (217, 'diab'),\n",
       " (27, 'drugtrt_copd'),\n",
       " (11, 'init_stat'),\n",
       " (308, 'init_wgt_kg'),\n",
       " (204, 'init_hgt_cm'),\n",
       " (25, 'end_stat'),\n",
       " (654, 'init_age'),\n",
       " (13, 'ethnicity'),\n",
       " (224, 'ethcat'),\n",
       " (476, 'end_bmi_calc'),\n",
       " (63, 'perip_vasc'),\n",
       " (3, 'exh_perit_access'),\n",
       " (2, 'exh_vasc_access'),\n",
       " (19, 'malig_tcr_ki'),\n",
       " (5, 'prev_tx'),\n",
       " (0, 'prev_ki_tx'),\n",
       " (279, 'func_stat_trr'),\n",
       " (1, 'malig_trr'),\n",
       " (985, 'creat_trr'),\n",
       " (36, 'first_wk_dial'),\n",
       " (964, 'serum_creat'),\n",
       " (45, 'pre_tx_txfus'),\n",
       " (39, 'txkid'),\n",
       " (18, 'don_retyp'),\n",
       " (334, 'da1'),\n",
       " (514, 'da2'),\n",
       " (544, 'db1'),\n",
       " (664, 'db2'),\n",
       " (414, 'ddr1'),\n",
       " (440, 'ddr2'),\n",
       " (118, 'ra1'),\n",
       " (383, 'ra2'),\n",
       " (260, 'rb1'),\n",
       " (525, 'rb2'),\n",
       " (222, 'rdr1'),\n",
       " (383, 'rdr2'),\n",
       " (92, 'amis'),\n",
       " (57, 'bmis'),\n",
       " (107, 'drmis'),\n",
       " (206, 'hlamis'),\n",
       " (36, 'npkid'),\n",
       " (8, 'nppan'),\n",
       " (768, 'age_don'),\n",
       " (22, 'hbv_core_don'),\n",
       " (4, 'hbv_sur_antigen_don'),\n",
       " (128, 'ethcat_don'),\n",
       " (81, 'abo_don'),\n",
       " (10, 'don_ty'),\n",
       " (35, 'gender_don'),\n",
       " (637, 'home_state_don'),\n",
       " (41, 'hist_cig_don'),\n",
       " (7, 'hist_hypertens_don'),\n",
       " (4, 'hist_cancer_don'),\n",
       " (18, 'diabetes_don'),\n",
       " (732, 'hgt_cm_don_calc'),\n",
       " (838, 'wgt_kg_don_calc'),\n",
       " (844, 'bmi_don_calc'),\n",
       " (0, 'end_stat_ki'),\n",
       " (39, 'abo_mat'),\n",
       " (765, 'age'),\n",
       " (732, 'distance'),\n",
       " (43, 'dial_trr'),\n",
       " (1013, 'cold_isch_ki'),\n",
       " (2135, 'gtime_ki'),\n",
       " (1031, 'dayswait_chron_ki'),\n",
       " (43, 'tx_procedur_ty_ki'),\n",
       " (74, 'cmv_igg'),\n",
       " (116, 'cmv_igm'),\n",
       " (127, 'ebv_serostatus'),\n",
       " (95, 'hbv_core'),\n",
       " (41, 'hbv_sur_antigen'),\n",
       " (78, 'hcv_serostatus'),\n",
       " (25, 'hiv_serostatus'),\n",
       " (41, 'cmv_status'),\n",
       " (41, 'prev_tx_any'),\n",
       " (9, 'share_ty'),\n",
       " (548, 'los'),\n",
       " (34, 'malig'),\n",
       " (519, 'hgt_cm_calc'),\n",
       " (743, 'wgt_kg_calc'),\n",
       " (776, 'bmi_calc'),\n",
       " (0, 'data_waitlist'),\n",
       " (1063, 'tx_yr'),\n",
       " (0, 'gtime_yr'),\n",
       " (110, 'outcome1'),\n",
       " (13, 'outcome2'),\n",
       " (11, 'composite')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in zip((list(gbm_form.feature_importance(\"split\"))), list(df.iloc[:, :-1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in categorical_vars:\n",
    "    df[c] = pd.Categorical(df[c]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    109514\n",
       "1     34133\n",
       "Name: death, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['death'].value_counts()\n",
    "# 1 there was no graft complication\n",
    "# 2 there was a graft complication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['px_stat'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_full = X\n",
    "y_form_full = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': (3, 15),\n",
    "    'min_child_weight': (1e-3, 1e+3),\n",
    "    'n_estimators': (1, 300),\n",
    "    'colsample_bytree': (1e-1, 1e+0),\n",
    "    'subsample': (0.4, 1),\n",
    "    'bagging_fraction': (0.5, 1),\n",
    "    'feature_fraction': (0.5, 1),\n",
    "    'min_split_gain': (0.1, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.39904213386\n",
      "{'bagging_fraction': 1.0, 'colsample_bytree': 0.10000000000000001, 'feature_fraction': 1.0, 'max_depth': 7, 'min_child_weight': 0.001, 'min_split_gain': 0.10000000000000001, 'n_estimators': 300, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "opt_form = BayesSearchCV(\n",
    "    lgb.LGBMRegressor(boosting_type='gbdt', objective='binary', metric='binary_loglos', categorical_feature=0),\n",
    "    params,\n",
    "    n_iter=100,\n",
    "    n_jobs=4\n",
    ")\n",
    "opt_form.fit(X_full, y_form_full)\n",
    "\n",
    "print(\"val. score: %s\" % opt_form.best_score_)\n",
    "print(opt_form.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_index(df, ['abo', 'perm_state', 'txkid', 'hbv_core_don', 'hbv_sur_antigen_don', 'abo_don', 'don_ty',\n",
    "#                     'home_state_don', 'cmv_igg', 'cmv_igm', 'ebv_serostatus', 'hbv_core',\n",
    "#                     'hbv_sur_antigen', 'hcv_serostatus', 'hiv_serostatus', 'cmv_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
